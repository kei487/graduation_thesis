\chapter{序論}

\section{研究背景}
\subsection{ロボティクスに対する社会的要請}

\subsubsection{少子高齢化と労働生産性の課題}
21世紀に入り，先進諸国においては少子高齢化に伴う生産年齢人口の減少が深刻な社会問題となっている．
特に日本においては，国立社会保障・人口問題研究所の推計によれば，
生産年齢人口（15〜64歳）は1995年をピークに減少傾向にあり，
2070年には約4,500万人（2020年比で約4割減）まで落ち込むことが予測されている\cite{ipss2023}．
この人口構造の変化は，経済成長の鈍化のみならず，社会インフラの維持そのものを脅かす要因となっている．


物流業界においては，「物流クライシス」と呼ばれる状況が顕在化している．
電子商取引（E-commerce）の爆発的な普及により，小口配送の需要が急増している．
国土交通省の調査によれば，宅配便取扱個数は年間50億個（2023年度）を超え，
過去10年間で約1.3倍に増加している\cite{mlit2024}
トラックドライバーや倉庫内作業員の不足は慢性化しており，
労働環境の悪化と配送網の維持困難が懸念されている．
また，製造業の現場においても，熟練工の引退に伴う技術継承の問題や，
単純搬送作業への人員配置の困難さが指摘されている．


さらに，医療・介護の分野では，高齢者人口の増加に対し，
介護従事者の数は圧倒的に不足している．
厚生労働省の推計では，2040年度には約272万人の介護職員が必要とされているが，
現状のままでは数十万人規模の供給不足に陥る可能性が指摘されている\cite{mhlw2024}．
病院内での検体搬送，リネン類の回収，あるいは介護施設における見守りや配膳など，
非接触かつ定型的な業務の負担軽減は，強い需要がある．


\subsubsection{業務自動化の変遷と限界}
こうした労働力不足を補う手段として，古くから業務の自動化（Automation）が進められてきた．
工場内物流においては，無人搬送車（Automated Guided Vehicle: AGV）が
1950年代にBarrett Electronics社によって開発されて以来\cite{ullrich2015}，
長年にわたり導入が進められてきた．
従来のAGVは，床面に敷設された磁気テープや反射テープ，
あるいは二次元コードといった物理的なガイドをセンサで読み取りながら走行する．


AGVは，環境が固定されており，かつタスクが定型的である場合には極めて高い効率と信頼性を発揮する．
しかしながら，その導入と運用には以下のような大きな制約が存在する．

\begin{enumerate}
    \item \textbf{インフラ敷設コスト}: 走行経路すべてにガイドを設置する必要があり，
	導入時の工事コストや期間が甚大である．
    \item \textbf{レイアウト変更の柔軟性欠如}: 製造ラインや倉庫のレイアウトを変更する際，
	ガイドの敷設し直しが必要となり，多大なコストとダウンタイムが発生する．
    \item \textbf{動的環境への非適応}: Fragapaneら\cite{fragapane2021}が指摘するように，
	想定された経路上に障害物が存在した場合，
	AGVはその場で停止することしかできず，回避して目的地へ向かうことができない．
\end{enumerate}

これらの制約は，人や有人フォークリフトが頻繁に行き交う物流倉庫や，
一般の人々が存在する病院・商業施設といった
「非構造化環境（Unstructured Environment）」へのロボット導入を阻む大きな障壁となっていた．

%\dummyfig{AGVとAMRの比較図}{3cm}

\subsubsection{自律移動ロボット（AMR）の台頭}
AGVの課題を克服する次世代の搬送ソリューションとして登場したのが，
自律移動ロボット（AMR）である．
AMRは，LiDAR（Light Detection and Ranging）や
カメラといった外部界センサを搭載し，周囲の環境をリアルタイムに認識する．
事前に作成した環境地図と現在のセンサ情報を照らし合わせることで
自身の位置を推定し，ガイドレスでの走行を可能にする．


AMRの最大の利点は，その「柔軟性」にある．
物理的なガイドを必要としないため，導入時の工事が不要であり，
ソフトウェア上の設定変更のみで走行エリアや経路を変更できる．
また，経路上に障害物を検知した際には，自律的に回避経路を生成し，
タスクを継続することが可能である．
この特性により，AMRは従来AGVが導入困難であった動的な環境への適用が進んでおり，
Industry 4.0の中核を担う技術として注目されている．


\subsection{自律移動ロボットの技術構成}

自律移動ロボットが実環境でタスクを遂行するためには，
ハードウェアとソフトウェアの両面において高度な統合が必要とされる．
本項では，AMRを構成する主要な要素技術について概説する．

\subsubsection{センシング技術}
ロボットが周囲の環境から情報を得るための技術である．
\begin{itemize}
    \item \textbf{LiDAR}: レーザー光を照射し，反射光が戻ってくるまでの時間（Time of Flight）
	や位相差から距離を計測する．
	2次元平面をスキャンする2D LiDARが主流であったが，
	近年では3次元点群を取得可能な3D LiDARの低価格化が進んでいる．
    \item \textbf{カメラ}: RGB画像に加え，深度情報を取得できるRGB-Dカメラや
	ステレオカメラが利用される．
	Visual SLAMや物体認識との親和性が高い．
    \item \textbf{オドメトリ（Odometry）}: 車輪の回転数（エンコーダ値）や
	IMU（慣性計測装置）のデータから，ロボットの相対的な移動量を推定する．
	短期的には高精度だが，累積誤差が生じるため単独では長距離移動に適さない．
\end{itemize}

\subsubsection{自己位置推定（Localization）技術の進展}
「今どこにいるか」を知る技術は，自律移動の根幹である．オドメトリの累積誤差を補正し，地図座標系上での絶対位置を特定するために，様々な手法が開発されてきた．


\paragraph{確率的ロボティクスの枠組み}
1990年代以降，Thrunらによって提唱された「確率的ロボティクス（Probabilistic Robotics）」は，センサのノイズや環境の不確実性を確率分布として扱うことで，ロバストな自己位置推定を可能にした．
代表的な手法として，モンテカルロ位置推定（Monte Carlo Localization: MCL）
あるいはパーティクルフィルタ（Particle Filter）がある．
これは，ロボットの存在確率分布を多数の粒子（パーティクル）で表現し，
センサ観測と動作モデルに基づいて粒子の重みと位置を更新する手法である．
MCLは，「大域的自己位置推定（Global Localization）」や
「誘拐ロボット問題（Kidnapped Robot Problem）」への対処能力を有しており，
現在のAMRのデファクトスタンダードとなっている．

%\dummyfig{パーティクルフィルタによる位置推定の概念図}{4cm}

\paragraph{SLAM (Simultaneous Localization and Mapping)}
地図を持たない未知の環境においては，自己位置推定と同時に環境地図の作成を行うSLAM技術が用いられる．
\begin{itemize}
    \item \textbf{LiDAR SLAM}: GMappingやCartographerなど，
	レーザーレンジファインダを用いたグリッドマップ生成手法．幾何的な精度が高い．
    \item \textbf{Visual SLAM}: ORB-SLAMなど，カメラ画像の特徴点を用いて
	疎な地図（Feature Map）を作成する．テクスチャの豊富な環境に強い．
\end{itemize}
さらに近年では，Graph-based SLAMと呼ばれる，
ロボットの姿勢（ノード）と観測制約（エッジ）をグラフ構造として表現し，
非線形最小二乗法によって全体最適化を行う手法が主流となっている．


\subsection{自己位置推定から経路計画へ}
自己位置推定技術の成熟により，
ロボットは環境内での自身の位置をセンチメートルオーダーの精度で特定できるようになった．
また，SLAM技術により，障害物の配置や通行可能な領域（Free Space）を表す
占有格子地図（Occupancy Grid Map）を自動的に生成することも可能となった．


しかし，「自分がどこにいるか」と「周囲がどうなっているか」を知ることは，
自律移動の必要条件ではあるが十分条件ではない．
ロボットが実際にタスクを遂行するためには，現在地（Start）から目的地（Goal）まで，
障害物を回避しつつ，かつ効率的（最短時間，最小エネルギーなど）
に到達するための軌道を決定しなければならない．
これが「経路計画（Path Planning）」である．


経路計画は，自己位置推定の結果と環境地図を入力とし，
ロボットのアクチュエータ（モータ）への制御指令を出力とする，
自律移動システムの「頭脳」に相当する部分である．
自己位置推定がいかに高精度であっても，
経路計画が不適切であれば，ロボットは遠回りをするか，
狭い通路で立ち往生するか，最悪の場合は動的障害物と衝突する危険性がある．


特に，社会実装が進むにつれて，ロボットが稼働する環境はより複雑化している．
\begin{itemize}
    \item 静的な障害物だけでなく，人や他のロボットが移動する動的環境．
    \item 路面状況によるスリップや，センサ計測の不確実性．
    \item 複数の目的地を効率よく巡回する等のタスクの複雑化．
\end{itemize}
これらの要因を考慮し，安全かつ最適な経路をリアルタイムに導出することは，
依然として困難かつ重要な研究課題である．
次節では，この経路計画に関する従来研究を概観し，
本研究で着目する価値反復法の位置付けを明らかにする．


% 経路計画技術は，現代社会において必要性が見込まれる
% 自律移動システムの要素技術である．
% 少子高齢化によって労働人口が減少している問題に対して，
% 自律移動システムを持つロボットが，
% 解決に寄与すると考えられている．
% ビルや商業施設の警備や，店舗や家屋の清掃，配膳，農業といった，
% 従来，人が行っていた作業は，移動を基礎とした作業である．
% そのため，自律移動システムは，
% これらの作業をロボットが代替する際に，要求される．


% 自律移動システムは，移動するロボットが，
% 人の操作を必要とせずに，安全に移動を行うシステムである．
% ロボットが安全に移動するためには，
% 障害物を回避ないしは停止し，ぶつからないことが求められる．
% 障害物は，建造物やロボットが乗り越えられない段差といった
% 短い時間で位置の変化しない固定障害物と，
% 人間や停車している車，看板といった短い時間で位置の変化する移動障害物
% の2種類に分けられる．
% 
% 自律移動システムには，
% 大別して自己位置推定，経路計画の2つの要素技術がある．
% 
% 
% 自己位置推定は，ロボット自身が
% 環境からセンサを通じて得られる情報から
% 環境内の自身の位置を推定する技術である．
% センサ情報から自身の位置を推定
% する技術である．
% には，MCL（Monte Carlo Localization）\cite{fox1999}
% が用いられる．
% 
% 
% 近年，先進国を中心とした少子高齢化の進行に伴い，
% 生産年齢人口の減少が深刻な社会問題となっている．
% 特に，物流倉庫における搬送業務，病院や介護施設における配膳・見回り業務，
% および大規模施設での清掃業務などにおいて，人手不足の解消が急務である．
% このような背景から，人間の代わりに自律的にタスクを遂行する
% 自律移動ロボット（Autonomous Mobile Robot: AMR）の導入と
% 実用化に大きな期待が寄せられている\cite{soumusho}．
% 
% 
% 自律移動ロボットが未知あるいは既知の環境下で目的地まで
% 安全かつ効率的に移動するためには，
% 主に「地図作成（Mapping）」，「自己位置推定（Localization）」，
% 「経路計画（Path Planning）」の3つの技術要素が不可欠である．
% このうち，自己位置推定に関しては，LiDAR（Light Detection and Ranging）
% やカメラなどのセンサ情報を用いて，
% 環境地図上での自身の位置と姿勢を推定する技術が確立されつつある．
% 特に，パーティクルフィルタを用いたモンテカルロ位置推定（MCL）や，
% 地図作成と自己位置推定を同時に行うSLAM（Simultaneous Localization and Mapping）技術の発展により，
% ロボットは高精度に自身の位置を特定することが可能となった\cite{thrun_probabilistic_2005}．
% 
% 
% しかしながら，ロボットが高精度に自己位置を推定できたとしても，
% それだけでは自律移動は実現できない．
% 現在地から目的地に至るまでの障害物を回避し，
% かつ移動時間やエネルギー消費などを最小化する最適な経路を導出する「経路計画」が必要となる．
% 経路計画は一般に，既知の環境地図に基づいて目的地までの大まかなルートを生成する
% 大域経路計画（Global Path Planning）と，
% 移動中の動的障害物を回避するための局所経路計画（Local Path Planning）に大別される．
% 大域経路計画においては，環境をグリッド地図やトポロジカルマップとして表現し，
% ダイクストラ法やA*アルゴリズムといったグラフ探索手法を用いるのが一般的である．
% これらの手法は計算コストが比較的低い反面，環境の不確実性を考慮した柔軟な動作生成や，
% 大域的なコスト分布に基づいた滑らかな制御指針を得る点においては課題が残る場合がある．
% 
% 
% そこで，ロボットが環境内のあらゆる状態において最適な行動指針（方策）を獲得するアプローチとして，
% マルコフ決定過程（MDP）に基づいた強化学習や動的計画法のアプローチが注目されている．
% 中でも動的計画法の一種である価値反復法（Value Iteration）は，
% 状態空間全体に対して最適な価値関数を計算することで，
% 大域的な最適経路を導出することが可能である．
% 本研究では，この価値反復法を用いた大域経路計画に着目し，
% その有効性と実装上の特性について議論する．





% 現在，経路計画にはよくA*アルゴリズムが用いられ，
% 経路追従と障害物回避にはDWA（Dynamic Window Approch）が用いられる．
% このように異なるアルゴリズムを用いることにより，計算が簡単になる反面
% 競合する可能性が残っている．
% そのため，経路計画と障害物回避を同時に行う手法として，
% ポテンシャル法がある．
% でも局所最適に陥る問題があり，価値反復はそれを解決する．



\section{従来研究}
\subsection{移動ロボットにおける経路計画の階層構造}

移動ロボットのナビゲーションシステムは，計算負荷と応答性のバランスを保つため，
一般的に以下の2つの階層に分離して設計される．

\begin{enumerate}
    \item \textbf{大域経路計画（Global Path Planning）}:
    環境全体の地図情報（事前地図）に基づき，スタートからゴールまでの大局的な最適ルートを生成する．
	更新頻度は比較的低く（数秒〜数分に1回，またはトポロジカルな変更時），
	静的な障害物の回避を主眼とする．
    \item \textbf{局所経路計画（Local Path Planning / Obstacle Avoidance）}:
    大域経路に追従しつつ，搭載センサで検知した未知の障害物や動的障害物をリアルタイムに回避する
	ための制御入力を生成する．
	更新頻度は高く（10Hz〜100Hz），ロボットの運動学的制約（Kinematics）や
	動力学的制約（Dynamics）を考慮する．
	Dynamic Window Approach (DWA) やModel Predictive Control (MPC) などが代表的である．
\end{enumerate}

本研究は，このうち「大域経路計画」に焦点を当てるものである．
局所計画器がいかに優秀であっても，大域的な指針が不適切
（例えば，物理的に通過不可能な狭路へ誘導してしまう，あるいはU字型の袋小路に迷い込む）であれば，
ロボットはゴールへ到達できない．
したがって，環境の大域的な構造とコストを正しく評価する大域経路計画アルゴリズムが不可欠である．


\subsection{決定論的アプローチによる経路計画}

大域経路計画の歴史は古く，
多くの手法は環境をグラフ構造としてモデル化する「グラフ探索問題」に帰着される．

\subsubsection{グリッドベースの探索手法}
環境地図を格子状（グリッド）に分割し，各セルをノード，隣接セルへの移動をエッジとみなす手法である．

\paragraph{Dijkstra法}
Edsger W. Dijkstraによって考案されたDijkstra法は，
非負の重み付きグラフにおける単一始点最短経路問題を解くアルゴリズムである．
スタートノードから順に，隣接ノードへの移動コストを累積し，
確定したノードから探索範囲を広げていく（幅優先探索のコスト付き版と言える）．
あるノード $n$ までの最小コストを $g(n)$ とするとき，
常に $g(n)$ が最小となるノードを展開することで，数学的に最短経路が保証される．
しかし，探索が全方位に均等に広がるため，ゴールの方角情報利用されず，探索範囲が膨大になる欠点がある．


\paragraph{A*アルゴリズム}
A*（A-Star）アルゴリズムは，Dijkstra法にヒューリスティック関数 $h(n)$ 
を導入することで探索を効率化した手法である．Hartらによって提案された．
評価関数 $f(n)$ を以下のように定義する．
\begin{equation}
    f(n) = g(n) + h(n)
\end{equation}
ここで，$g(n)$ はスタートからノード $n$ までの実コスト，
$h(n)$ はノード $n$ からゴールまでの推定コスト（ヒューリスティック）である．
移動ロボットの場合，$h(n)$ として現在のセルからゴールセルまでの
ユークリッド距離やマンハッタン距離が用いられる．
$h(n)$ が実際の最短コストを決して上回らない（許容的，Admissibleである）場合，
A*アルゴリズムは最適解を保証しつつ，Dijkstra法よりも少ないノード展開数で解に到達できる．
現在でも最も広く使われている標準的なアルゴリズムである．

%\dummyfig{Dijkstra法とA*アルゴリズムの探索範囲比較}{5cm}

\subsubsection{サンプリングベースの手法}
高次元の構成空間（Configuration Space: C-Space）を持つロボット（多関節アームなど）や，
広大な環境においては，グリッドベースの手法は計算量が爆発する．
これに対し，空間内の点をランダムにサンプリングしてグラフを構築する手法が提案されている．


\paragraph{RRT (Rapidly-exploring Random Tree)}
LaValleによって提案されたRRTは，
ランダムにサンプリングされた点に向かってツリーを拡張していくことで，空間を急速に被覆する手法である．
非ホロノミック拘束（自動車のような移動制約）を持つロボットの経路計画にも適用しやすい．
しかし，RRTによって生成される経路は最適性が保証されず，
ジグザグな無駄の多い経路になりがちである．
これを改良したRRT*（RRT-Star）は，漸近的最適性を有するが，収束には時間を要する．


\paragraph{PRM (Probabilistic RoadMap)}
PRMは，学習フェーズで空間全体にランダムなノードを配置してロードマップ（グラフ）を構築し，
クエリフェーズでスタートとゴールをそのロードマップに接続して経路を探索する手法である．
多点間の移動を繰り返すようなタスクに適しているが，
狭い通路（Narrow Passage）の通過が困難であるという問題が知られている．


\subsection{価値反復法（Value Iteration）}

前節で述べたA*やRRTは，基本的に「ある特定のスタートからゴールへの一本のパス」を見つける手法である．
これに対し，本研究で取り扱う「価値反復法」は，環境内の**すべての状態（位置）**について，
ゴールへの最適方策を計算するアプローチである．
この手法は，環境の不確実性を確率的に扱うことが可能であり，
外乱に対して極めて堅牢（Robust）なナビゲーションを実現する．


\subsubsection{マルコフ決定過程（MDP）による定式化}
価値反復法を理解するためには，その基礎となるマルコフ決定過程（Markov Decision Process: MDP）
の定義が必要である．
MDPは，エージェントが環境と相互作用しながら学習・行動決定を行うための数理モデルであり，
以下の4つの要素の組 
$\langle \mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R} \rangle$ で定義される．

\begin{enumerate}
    \item \textbf{状態集合 $\mathcal{S}$ (State Space)}:
    ロボットが取り得るすべての状態の集合．2次元グリッドマップ上での経路計画の場合，
	各グリッドセル $(x, y)$ が一つの状態 $s \in \mathcal{S}$ に対応する．
	さらに，ロボットの方位 $\theta$ を含めて $(x, y, \theta)$ を状態とすることもある．

    \item \textbf{行動集合 $\mathcal{A}$ (Action Space)}:
    各状態でロボットが選択可能な行動の集合．
	グリッドマップ上では，隣接する8近傍（上下左右＋斜め）への移動や，
	その場での停止などが行動 $a \in \mathcal{A}$ となる．

    \item \textbf{遷移確率 $\mathcal{P}_a(s, s')$ (Transition Probability)}:
    状態 $s$ で行動 $a$ を選択したときに，次の時刻に状態 $s'$ へ遷移する確率．
    \begin{equation}
        \mathcal{P}_a(s, s') = \Pr(S_{t+1}=s' \mid S_t=s, A_t=a)
    \end{equation}
    決定論的な環境（A*などが想定する世界）では，ある行動を行えば100\%意図した隣接セルへ移動する．
	しかし実環境では，タイヤのスリップや制御誤差により，意図したセルへ移動できない場合がある．
	MDPではこの不確実性を確率分布として明示的にモデル化できる．
	例えば，「前進」を選択しても，10\%の確率で「横滑り」する，といった表現が可能である．

    \item \textbf{報酬関数 $\mathcal{R}_a(s, s')$ (Reward Function)}:
    状態遷移に伴って得られる即時報酬（またはコスト）．
	経路計画問題においては，通常「コストの最小化」または「負の報酬の最大化」として定式化される．
    例えば，ゴール状態に到達したときに大きな正の報酬を与え，
	障害物に衝突したときに大きな負の報酬（ペナルティ）を与える．
	また，移動にかかる時間やエネルギーを表現するため，
	各ステップごとにわずかな負の報酬（ステップコスト）を与える．
\end{enumerate}

\subsubsection{ベルマン方程式と価値関数}
MDPの目的は，各状態でどのような行動をとるべきかというルール，
すなわち「方策（Policy） $\pi: \mathcal{S} \to \mathcal{A}$」を見つけることである．
最適な方策 $\pi^*$ を見つけるために，「状態価値関数 $V^\pi(s)$」を導入する．
これは，ある状態 $s$ からスタートし，方策 $\pi$ に従って行動し続けたときに
得られる将来の報酬の総和（期待値）である．


割引率を $\gamma$ ($0 \le \gamma < 1$) とすると，価値関数は以下のように定義される．
\begin{equation}
    V^\pi(s) = \mathbb{E} \left[ \sum_{t=0}^{\infty} \gamma^t R_{t+1} \mid S_0 = s, \pi \right]
\end{equation}


最適な方策 $\pi^*$ に従ったときの価値関数を最適状態価値関数 $V^*(s)$ と呼ぶ．
$V^*(s)$ は，以下のベルマン最適方程式（Bellman Optimality Equation）を満たす．
\begin{equation}
    V^*(s) = \max_{a \in \mathcal{A}} \sum_{s' \in \mathcal{S}} 
	\mathcal{P}_a(s, s') \left[ \mathcal{R}_a(s, s') + \gamma V^*(s') \right]
    \label{eq:bellman_opt}
\end{equation}


この方程式は再帰的な構造をしており，
「ある状態の価値は，そこで最適な行動をとった際に期待される即時報酬と，
遷移先の状態の価値の割引和によって決まる」ことを意味している．

\subsection{価値反復アルゴリズム}
ベルマン最適方程式 (\ref{eq:bellman_opt}) を用いて，
反復計算により $V^*(s)$ を求める手法が価値反復法（Value Iteration）である．
アルゴリズムの手順は以下の通りである．

\begin{enumerate}
    \item \textbf{初期化}: すべての状態 $s$ について，$V(s)$ を任意の値（通常は0）に初期化する．
    \item \textbf{反復更新}: 以下の更新式を，すべての状態 $s$ に対して適用する．
    \begin{equation}
        V_{k+1}(s) \leftarrow \max_{a \in \mathcal{A}} \sum_{s' \in \mathcal{S}} 
	\mathcal{P}_a(s, s') \left[ \mathcal{R}_a(s, s') + \gamma V_k(s') \right]
    \end{equation}
    ここで $k$ は反復回数を表す．
    \item \textbf{収束判定}: 全状態における価値関数の更新量 $|V_{k+1}(s) - V_k(s)|$ の最大値が，
	事前に定めた閾値 $\epsilon$ 未満になれば停止する．
    \item \textbf{方策抽出}: 収束した価値関数 $V^*(s)$ を用い，
	各状態で価値を最大化する行動を選択する貪欲方策（Greedy Policy）を得る．
    \begin{equation}
        \pi^*(s) = \operatorname*{argmax}_{a \in \mathcal{A}} \sum_{s' \in \mathcal{S}} 
	\mathcal{P}_a(s, s') \left[ \mathcal{R}_a(s, s') + \gamma V^*(s') \right]
    \end{equation}
\end{enumerate}

この計算により，環境内のあらゆる場所からゴールへ向かうための最適な「勾配」が得られる．
これはポテンシャル場に似ているが，ポテンシャル法が抱える「局所解（Local Minima）」の問題
（ゴール以外の窪みにハマって出られなくなる現象）が発生しないという強力な数学的保証がある．
なぜなら，ベルマン方程式による更新は，大域的な最適性を伝播させる処理だからである．

%\dummyfig{価値関数の伝播と収束プロセスの可視化}{6cm}

\subsection{価値反復法の移動ロボットへの適用事例と課題}

\subsubsection{古典的な適用とナビゲーション関数}
移動ロボットの経路計画において，価値反復法の概念を早期に取り入れた研究として，
KonoligeによるGradient Method\cite{konolige2000gradient}がある．
彼は，障害物との距離に基づくコストマップ上で波及法（Wavefront Propagation）に類似した計算を行い，
ゴールからの距離（コスト）を表すナビゲーション関数（Navigation Function）を作成した．
この関数は，実質的に決定論的MDP（$\gamma=1$, 遷移確率1.0）における価値関数と等価である．
ロボットはこの関数の勾配（Gradient）に従って降下することで，
滑らかかつ最短の経路でゴールへ到達できる．
この手法は，A*などの探索手法が「離散的なセルの列」を経路として出力するのに対し，
連続的なベクトル場を生成するため，制御系への入力として扱いやすいという利点がある．


\subsubsection{不確実性の考慮と確率的MDP}
Thrunら\cite{thrun2005probabilistic}は，著書『Probabilistic Robotics』において，
センサノイズやアクチュエータ誤差を考慮したMDPベースのプランニングの重要性を説いている．
例えば，狭い通路を通る際，A*アルゴリズムなどの幾何的な最短経路探索では，
壁ギリギリを通るルートを選択しがちである．
しかし，実ロボットには移動誤差があるため，壁に衝突するリスクが高い．
確率的な遷移モデル $\mathcal{P}$ を組み込んだ価値反復法を用いると，
壁際での移動は「衝突して大きなペナルティを受ける確率がある行動」として評価される．
その結果，多少遠回りであっても，壁から距離を取った安全な広い通路を選択するような，
リスク回避的な経路（Risk-Aware Path）が自然に生成される．
これは，安全性が最優先されるサービスロボットにおいて極めて重要な特性である．


\subsubsection{計算コストの問題と高速化手法}
価値反復法の最大の欠点は，計算コストである．
状態空間 $\mathcal{S}$ のサイズに対して計算量が線形
（1回の反復あたり $O(|\mathcal{S}||\mathcal{A}|)$）に増加する．
広大な環境を高い解像度でグリッド化すると，状態数は数百万から数千万に達し，
リアルタイムでの再計算が困難になる．


これに対し，いくつかの高速化手法が提案されている．
\begin{itemize}
    \item \textbf{Prioritized Sweeping}: 価値の変化が大きかった状態の周辺のみを優先的に更新する手法．
    \item \textbf{GPUによる並列化}: 各状態の更新計算は独立性が高いため，
	GPU（Graphics Processing Unit）を用いた並列計算と相性が良い．
	近年ではCUDAを用いた実装により，数百万セルの更新を数ミリ秒で行う研究も報告されている．
    \item \textbf{階層化（Hierarchical MDP）}: 環境を粗いトポロジカルな領域に分割し，
	上位層で大まかな遷移を決定し，下位層で詳細な価値反復を行う手法．
\end{itemize}


\subsubsection{深層強化学習との融合}
近年では，Tamarらが提案したValue Iteration Networks (VIN)\cite{tamar2016value}のように，
価値反復の計算プロセス自体を微分可能なニューラルネットワークの層として組み込む研究が盛んである．
これにより，生のセンサ画像（入力）から，障害物のコストマップ（中間表現），
そして最適な移動方向（出力）までをEnd-to-Endで学習することが可能となる．
これは，未知の環境における探索能力や，
人混みの中でのナビゲーションといった複雑なタスクにおいて成果を上げている．

\subsection{本研究の目的と構成}

\subsubsection{解決すべき課題}
以上の従来研究の調査から，価値反復法は移動ロボットの大域経路計画において
「大域的最適性の保証」「局所解の回避」「不確実性への対処」という優れた特性を持つことが確認された．
しかしながら，実環境での運用を考えた場合，以下の課題が依然として未解決，あるいは改善の余地がある．

\begin{enumerate}
    \item \textbf{動的環境へのリアルタイム追従性}: 環境の変化（ドアの開閉，荷物の移動など）に対し，
	全状態の価値関数を再計算するには時間がかかる．
	部分的な更新で整合性を保つ効率的なアルゴリズムが必要である．
    \item \textbf{コスト関数の設計困難性}: 「安全性」や「社会的受容性（人への配慮）」
	といった抽象的な指標を，どのような報酬関数として設計するかは自明ではない．
	逆強化学習（Inverse Reinforcement Learning）などのアプローチもあるが，計算負荷が高い．
    \item \textbf{3次元空間への拡張}: ドローンや不整地走行ロボットへの適用を考えた際，
	状態空間の次元爆発をどう抑えるかが課題となる．
\end{enumerate}


\section{研究目的}
価値反復ROSパッケージを用いたナビゲーションにおいて，
走り出しまでの時間を短縮することで
移動にかかる時間を短縮することを目的とする．


\section{論文の構成}
章では，問題設定と価値反復アルゴリズム，A*アルゴリズムについて述べ，
章では，提案手法，章では，実験について述べる．
章でまとめる．

