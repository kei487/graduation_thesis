\section{従来研究}
\subsection{移動ロボットにおける2種の経路計画器}

移動ロボットのナビゲーションにおける経路計画器は，
動的に目的地が決まる場合，
計算負荷と性能のバランスを保つため，
一般的に以下の2つの階層に分離して設計される．
目的地が固定されている場合は，
大域経路計画をアルゴリズムを使わずに決定することがある．

\begin{enumerate}
    \item \textbf{大域経路計画（Global Path Planning）}:
    環境全体の地図情報（事前地図）に基づき，スタートからゴールまでの大局的な最適ルートを生成する．
	更新頻度は比較的低く（数秒〜数分に1回，またはトポロジカルな構造の変更時），
	静的な障害物の回避を行う．
    \item \textbf{局所経路計画（Local Path Planning / Obstacle Avoidance）}:
    大域経路に追従しつつ，搭載されたセンサで検知した未知の障害物や動的障害物をリアルタイムに回避する
	ための制御入力を生成する．
	更新頻度は高く（10Hz〜100Hz），ロボットの運動学的制約（Kinematics）や
	動力学的制約（Dynamics）を考慮する．
	Dynamic Window Approach (DWA) やModel Predictive Control (MPC) などが代表的である．
\end{enumerate}


理由は後述するが，本研究は，このうち大域経路計画を取り扱う．
次章から大域経路計画の各手法について述べる．


\subsection{決定論的アプローチによる経路計画}
環境を，各要素を表すノードとそのノード同士の関係を表したエッジからなるグラフ構造として
モデル化することで，大域経路計画をグラフ探索問題に帰着できる．
素朴に大域経路計画を考えたとき，スタートからゴールへの一本のパスを見つける手法が考えられる．
グラフ探索問題は，与えられたグラフ内に，スタートとゴールのノードが設定され，
エッジをたどりノードを移動してゆき，最短の移動で，
ゴールのノードにたどり着く1通りのノードとエッジの列を求める問題である．


\subsubsection{グリッドベースの探索手法}
環境の地図を格子状（グリッド）に分割し，各セルをノード，
隣接セルへの移動をエッジとみなす手法である．
多くの場合，セルには，障害物があり通行不可能，障害物がなく通行可能，不明
の3つのモードがあり，障害物がなく通行可能なセルだけをたどる経路を算出することが求められる．

\paragraph{Dijkstra法}
Edsger W. Dijkstraによって考案されたDijkstra法は，
非負の重み付きグラフにおける単一始点最短経路問題を解くアルゴリズムである．
スタートノードから順に，隣接ノードへの移動コストを累積し，
確定したノードから探索範囲を広げていく（幅優先探索のコスト付き版と言える）．
あるノード $n$ までの最小コストを $g(n)$ とするとき，
常に $g(n)$ が最小となるノードを展開することで，数学的に最短経路が保証される．
しかし，探索が全方位に均等に広がるため，ゴールの方角情報利用されず，探索範囲が膨大になる欠点がある．

\paragraph{A*アルゴリズム}
A*（A-Star）アルゴリズムは，Dijkstra法にヒューリスティック関数 $h(n)$ 
を導入することで探索を効率化した手法である．Hartらによって提案された．
評価関数 $f(n)$ を以下のように定義する．
\begin{equation}
    f(n) = g(n) + h(n)
\end{equation}
ここで，$g(n)$ はスタートからノード $n$ までの実コスト，
$h(n)$ はノード $n$ からゴールまでの推定コスト（ヒューリスティック）である．
移動ロボットの場合，$h(n)$ として現在のセルからゴールセルまでの
ユークリッド距離やマンハッタン距離が用いられる．
$h(n)$ が実際の最短コストを決して上回らない（許容的な，Admissible）場合，
A*アルゴリズムは最適解を保証しつつ，Dijkstra法よりも少ないノード展開数で解に到達できる．
現在でも最も広く使われている標準的なアルゴリズムである．

%\dummyfig{
\begin{figure}
  \centering
  \includegraphics[width=0.8\linewidth]{example-image-16x9.pdf}
  \caption{Dijkstra法とA*アルゴリズムの探索範囲比較}
\end{figure}


\subsubsection{サンプリングベースの手法}
高次元の構成空間（Configuration Space: C-Space）を持つロボット（多関節アームなど）や，
広大な環境においては，グリッドベースの手法は次元の呪いにより，グラフが極めて大きいものになり
探索にかかる計算量が多いものとなる．
これに対し，空間内の点をランダムにサンプリングしてグラフを構築する手法が提案されている．

\paragraph{RRT (Rapidly-exploring Random Tree)}
LaValleによって提案されたRRTは，
ランダムにサンプリングされた点に向かってツリーを拡張していくことで，空間を急速に被覆する手法である．
非ホロノミック拘束（自動車のような移動制約）を持つロボットの経路計画にも適用しやすい．
しかし，RRTによって生成される経路は最適性が保証されず，
ジグザグな無駄の多い経路になりがちである．
これを改良したRRT*（RRT-Star）は，漸近的最適性を有するが，収束には時間を要する．

\paragraph{PRM (Probabilistic RoadMap)}
PRMは，学習フェーズで空間全体にランダムなノードを配置してロードマップ（グラフ）を構築し，
クエリフェーズでスタートとゴールをそのロードマップに接続して経路を探索する手法である．
多点間の移動を繰り返すようなタスクに適しているが，
狭い通路（Narrow Passage）の通過が困難であるという問題が知られている．


\subsection{ポテンシャル法とナビゲーション関数}
グラフ探索やサンプリング手法が「経路（Path）」という離散的な線の集合を出力するのに対し，
環境全体にベクトル場（Vector Field）を定義し，その流れに乗って移動するアプローチが存在する．

\subsubsection{人工ポテンシャル法 (Artificial Potential Fields)}
Khatib\cite{khatib1986real}によって提案された人工ポテンシャル法（APF）は，
ロボットを仮想的な荷電粒子とみなし，
ゴールからの「引力」と障害物からの「斥力」を合成したポテンシャル場を構築する手法である．
ロボットはポテンシャルの勾配（Gradient）に従って最もエネルギーが低い方向へ移動するだけでよいため，
計算負荷が非常に軽く，リアルタイムな障害物回避に適している．
しかし，APFには重大な欠点がある．
それは「局所解（Local Minima）」の問題である．
U字型の障害物などに遭遇した場合，引力と斥力が釣り合ってしまい，
ゴールに到達する前に極小値で停止してしまう現象が発生する．

\subsubsection{ナビゲーション関数 (Navigation Functions)}
局所解の問題を解決するために，KoditschekとRimon\cite{koditschek1990robot}は
「ナビゲーション関数（Navigation Function）」の概念を提唱した．
これは，幾何学的な構成空間において，ゴールのみを唯一の大域的最小点（Global Minimum）とし，
その他すべての停留点が不安定な鞍点（Saddle Point）となるように
設計された特殊なポテンシャル関数である．
ナビゲーション関数が構築できれば，その勾配に従うだけで，
ロボットはどのような初期位置からでも必ずゴールへ到達できることが数学的に保証される．

グリッドマップ上におけるナビゲーション関数の実装例として，
KonoligeのGradient Method\cite{konolige2000gradient}が挙げられる．
これは，Dijkstra法や波及法（Wavefront Propagation）を用いて
各グリッドセルからゴールまでの「真の距離コスト」を計算し，
これをポテンシャルとみなすものである．
こうして得られた場は局所解を持たず，大域的に最適な経路情報を内包している．


\subsection{価値反復法（Value Iteration）}
これらの決定論的な大域経路計画に対し，
本研究で取り扱う価値反復法は，環境内のすべての状態（位置と向き）と行動を対応付けた
方策を計算するアプローチである．
この手法は，環境の不確実性を確率的に扱うことが可能であり，
外乱に対してロバストなナビゲーションを実現する．


\subsubsection{マルコフ決定過程（MDP）による定式化}
価値反復法を理解するためには，その基礎となるマルコフ決定過程（Markov Decision Process: MDP）
の定義が必要である．
MDPは，エージェントが環境と相互作用しながら学習・行動決定を行うための数理モデルであり，
以下の4つの要素の組 
$\langle \mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R} \rangle$ で定義される．

% \begin{enumerate}
%     \item \textbf{状態集合 $\mathcal{S}$ (State Space)}:
%     ロボットが取り得るすべての状態の集合．2次元グリッドマップ上での経路計画の場合，
% 	各グリッドセル $(x, y)$ が一つの状態 $s \in \mathcal{S}$ に対応する．
% 	さらに，ロボットの方位 $\theta$ を含めて $(x, y, \theta)$ を状態とすることもある．
% 
%     \item \textbf{行動集合 $\mathcal{A}$ (Action Space)}:
%     各状態でロボットが選択可能な行動の集合．
% 	グリッドマップ上では，隣接する8近傍（上下左右＋斜め）への移動や，
% 	その場での停止などが行動 $a \in \mathcal{A}$ となる．
% 
%     \item \textbf{遷移確率 $\mathcal{P}_a(s, s')$ (Transition Probability)}:
%     状態 $s$ で行動 $a$ を選択したときに，次の時刻に状態 $s'$ へ遷移する確率．
%     \begin{equation}
%         \mathcal{P}_a(s, s') = \Pr(S_{t+1}=s' \mid S_t=s, A_t=a)
%     \end{equation}
%     決定論的な環境（A*などが想定する世界）では，ある行動を行えば100\%意図した隣接セルへ移動する．
% 	しかし実環境では，タイヤのスリップや制御誤差により，意図したセルへ移動できない場合がある．
% 	MDPではこの不確実性を確率分布として明示的にモデル化できる．
% 	例えば，「前進」を選択しても，10\%の確率で「横滑り」する，といった表現が可能である．
% 
%     \item \textbf{報酬関数 $\mathcal{R}_a(s, s')$ (Reward Function)}:
%     状態遷移に伴って得られる即時報酬（またはコスト）．
% 	経路計画問題においては，通常「コストの最小化」または「負の報酬の最大化」として定式化される．
%     例えば，ゴール状態に到達したときに大きな正の報酬を与え，
% 	障害物に衝突したときに大きな負の報酬（ペナルティ）を与える．
% 	また，移動にかかる時間やエネルギーを表現するため，
% 	各ステップごとにわずかな負の報酬（ステップコスト）を与える．
% \end{enumerate}





\subsection{価値反復アルゴリズム}
ベルマン最適方程式 (\ref{eq:bellman_opt}) を用いて，
反復計算により $V^*(s)$ を求める手法が価値反復法（Value Iteration）である．
これはポテンシャル場に似ているが，ポテンシャル法が抱える局所解（Local Minima）の問題
（ゴール以外の窪みにハマって出られなくなる現象）が発生しないという強力な数学的保証がある．

%\dummyfig{価値関数の伝播と収束プロセスの可視化}{6cm}


\subsubsection{不確実性の考慮と確率的MDP}
Thrunらの著書『Probabilistic Robotics』\cite{thrun2005}において，
センサノイズやアクチュエータ誤差を考慮したMDPベースのプランニングの重要性が説かれている．
例えば，狭い通路を通る際，A*アルゴリズムなどの幾何的な最短経路探索では，
壁ギリギリを通るルートを選択しがちである．
しかし，実ロボットには移動誤差があるため，壁に衝突するリスクが高い．
確率的な遷移モデル $\mathcal{P}$ を組み込んだ価値反復法を用いると，
壁際での移動は衝突して大きなペナルティを受ける確率がある行動として評価される．
その結果，多少遠回りであっても，壁から距離を取った安全な広い通路を選択するような，
リスク回避的な経路（Risk-Aware Path）が自然に生成される．
これは，安全性が最優先されるサービスロボットにおいて極めて重要な特性である．


\subsubsection{計算コストの問題と高速化手法}
価値反復法の最大の欠点は，計算コストである．
状態空間 $\mathcal{S}$ のサイズに対して計算量が線形
（1回の反復あたり $O(|\mathcal{S}||\mathcal{A}|)$）に増加する．
広大な環境を高い解像度でグリッド化すると，状態数は数百万から数千万に達する．


上田らは，将来的には，計算機の性能が向上し，この計算コストの問題が解決されるとして
現在の移動ロボットで使われるミドルウェアのROS上で実装した．


%これに対し，いくつかの高速化手法が提案されている．
%\begin{itemize}
%    \item \textbf{Prioritized Sweeping}: 価値の変化が大きかった状態の周辺のみを優先的に更新する手法．
%    \item \textbf{GPUによる並列化}: 各状態の更新計算は独立性が高いため，
%	GPU（Graphics Processing Unit）を用いた並列計算と相性が良い．
%	近年ではCUDAを用いた実装により，数百万セルの更新を数ミリ秒で行う研究も報告されている．
%    \item \textbf{階層化（Hierarchical MDP）}: 環境を粗いトポロジカルな領域に分割し，
%	上位層で大まかな遷移を決定し，下位層で詳細な価値反復を行う手法．
%\end{itemize}


% \subsubsection{深層強化学習との融合}
% 近年では，Tamarらが提案したValue Iteration Networks (VIN)\cite{tamar2016value}のように，
% 価値反復の計算プロセス自体を微分可能なニューラルネットワークの層として組み込む研究が盛んである．
% これにより，生のセンサ画像（入力）から，障害物のコストマップ（中間表現），
% そして最適な移動方向（出力）までをEnd-to-Endで学習することが可能となる．
% これは，未知の環境における探索能力や，
% 人混みの中でのナビゲーションといった複雑なタスクにおいて成果を上げている．

