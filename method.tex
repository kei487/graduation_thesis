\chapter{提案手法}\label{chap:method}

\section{価値反復とA*の組み合わせ}
A*と価値反復を並列に計算し，
A*の計算結果を価値反復に適用する．
既存の価値反復と
並行でA*探索を実行し，図\ref{fig:propose}(c)のように，
A*の見つけた経路沿いに
$V$の値を書き換えるというものである．
図のようにロボットが行動を開始する状態から
目的地まで，$V$の値を少しずつ減らしていくように
書き換えることで，価値反復が経路を見つける前に，
ロボットを目的地に向かわせるようにする．


$V$の書き換えは，A*の見つけた経路沿いの各$s$に対して，
\begin{align}
	V(s) \longleftarrow K f(s) \label{eq:a-star_weight}
\end{align}
という代入の式を用いて行う．
$K$は定数であり，$f$は$s$から
目的地までの経路上での道のりである．

この方法では，ロボットと目的地の間の
環境が迷路のようになっていなければ，
A*で見つかる経路がほぼ最適な経路となり，
価値反復のみの場合よりもロボットが速やかに
目的地に向かえるようになる．
一方，迷路のような環境だと，
たとえばA*で見つけた経路が遠回りで，
そのあとで価値反復がよりよい経路を見つけると，
目的地までの時間が増えてしまう可能性がある．

また，A*がほぼ最適な経路を見つけられる場合，
価値反復は大域計画に対しては必須ではなくなる．
しかし，A*の見つけた経路の最適化や，
未知の障害物が現れた場合の$V$の修正や
迂回先の$V$の計算に必要となる．

\section{3D A*の適用}
3Dのほうがよくなるのではないか

本稿では，$xy\theta$空間でのA*探索と価値反復を組み合わせる．
ヒューリスティック関数$H$については，
\cite{nakamura2024}での平面上のユークリッド距離を計算するものから，
\begin{align}
	H(s) \triangleq W_1 \sqrt{  (x_\text{c} - x_\text{g})^2 + (y_\text{c} - y_\text{g})^2 }
	+ W_2 | \theta_\text{c} - \theta_\text{g} | \label{eq:3d-astar-heurisic}
\end{align}
に変更する．
ここで，
$(x_\text{c}, y_\text{c}, \theta_\text{c})$は各離散状態の中心の座標，
$(x_\text{g}, y_\text{g})$は目的地の中心地点の$xy$座標，
$\theta_\text{c} - \theta_\text{g}$は，$(x_\text{c}, y_\text{c}, \theta_\text{c})$
から見た$(x_\text{g}, y_\text{g})$の方角である．
$W_1, W_2$は定数である．
$W_1$と$W_2$の比は，ロボットが一定時間あたりに移動できる距離と方向転換できる角度の比で決まる．
%これは，平面上のマンハッタン距離と角度の差の和になっている．
%上田メモ↑: 「これ」がなにを指してるか不明でした．


A*で算出した暫定経路の$V$への適用は，
\cite{nakamura2024}と同じく式（\ref{eq:a-star_weight}）で行う．
ただし，$V$の値を変更する対象となる状態$s$については，
A*の算出した$xy\theta$空間中の経路をそのまま使うように変更した．
また，$f$の値については，
A*の算出した経路上での
$s$とゴールまでの離散状態数とした．
A*には，ヒューリスティック関数を
「許容的」にすると最適な経路が見つかるという性質がある．
ただし，許容的な場合には経路の探索に
時間がかかる可能性がある．
これについては次章の実験で調査する．

